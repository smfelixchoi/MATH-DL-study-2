{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e198236b",
   "metadata": {},
   "source": [
    "# Solving Linear Regression \n",
    "\n",
    "- Only Training set, No Test points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7776a0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c61f7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "with open('data.pickle', 'rb') as f:\n",
    "    data_load = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c039be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4183967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3360, 4) (3360,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74133960",
   "metadata": {},
   "source": [
    "### Analytic Solution\n",
    "\n",
    "Let $X \\in \\mathbb{R}^{N \\times d}$ be the ***design matrix*** of the data,\n",
    "that is, the $i$ th **row vector** of $X$ is $\\hat{x^i} = (1, x^i)$.\n",
    "\n",
    "Let $y \\in \\mathbb{R}^N$ be the **row vector** consisting of labels of data.\n",
    "\n",
    "Then, the loss function $L(w)$ can be written as the following vector notation:\n",
    "$$L(w) = \\frac{1}{2N}\\sum_{i=1}^N (y_i- w x_i^\\top)^2=\\frac{1}{2N}(y - w X^\\top) (y - wX^\\top)^\\top.$$\n",
    "\n",
    "Since the loss function is convex w.r.t $w$, we can find the minimum by differentiating the function w.r.t $w$.\n",
    "\n",
    "$$\\nabla_{w} L(w) = \\frac{1}{N} (-yX + wX^\\top X)$$\n",
    "\n",
    "Therefore, if $X^\\top X$ is invertible, the analytic optimal solution is\n",
    "$$ \\hat{w} = yX(X^\\top X)^{-1}. $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1485d2bb",
   "metadata": {},
   "source": [
    "```np.linalg.solve(A,b)```\n",
    "\n",
    "- It finds a solution x for the linear equation Ax = b.\n",
    "- Here, x is considered to be a column vector. Thus we take transpose to the equation above.\n",
    "\n",
    "$$\\nabla_{w} L(w) = 0 \\quad \\Leftrightarrow \\quad w(X^\\top X)=yX \\quad \\Leftrightarrow \\quad (X^\\top X)w^\\top = X^\\top y^\\top$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a14c104d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.55513795 -4.01374667  3.66918128 -6.52875621]\n"
     ]
    }
   ],
   "source": [
    "w = np.linalg.solve(X.T @ X, X.T @ y.T)\n",
    "\n",
    "print(w)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a038c189",
   "metadata": {},
   "source": [
    "### Wrong Answer! Why?\n",
    "\n",
    "- We consider each row vector to have $1$ in the first entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4405c5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.zeros((X.shape[0], X.shape[1]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7e9955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X.shape[0]):\n",
    "    temp = list(X[i])\n",
    "    temp.insert(0, 1)  #List.insert(index, value) index에 value값을 넣기\n",
    "    Z[i] = np.array(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ffd4288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.91055003  3.00048444 -4.01521986  1.00538649 -6.98619243]\n"
     ]
    }
   ],
   "source": [
    "w = np.linalg.solve(Z.T@Z, Z.T@y.T)\n",
    "\n",
    "print(w)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd17d355",
   "metadata": {},
   "source": [
    "### Gradient Descent Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce243fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM=4\n",
    "OUTPUT_DIM=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50dc24a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X, weights):\n",
    "    pred = np.matmul(weights, X.T)\n",
    "    return pred\n",
    "\n",
    "def MSE(X, y, pred):\n",
    "    N = X.shape[0]\n",
    "    loss = np.sum((pred-y)**2) / (2*N)\n",
    "    return loss\n",
    "\n",
    "def compute_grads(X, y, pred):\n",
    "    N     = X.shape[0]\n",
    "    grads = (1/N)*(-np.matmul(y,X) + np.matmul(pred, X))\n",
    "    return grads\n",
    "\n",
    "def update_weights(weights, grads, LR):\n",
    "    weights -= LR*grads\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3980ae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE= 30\n",
    "EPOCHS=100\n",
    "LR = 0.001\n",
    "\n",
    "weights= np.random.randn(OUTPUT_DIM,INPUT_DIM+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd8ed066",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 Completed, Loss: 90.371\n",
      "EPOCH 2 Completed, Loss: 46.376\n",
      "EPOCH 3 Completed, Loss: 32.512\n",
      "EPOCH 4 Completed, Loss: 28.221\n",
      "EPOCH 5 Completed, Loss: 23.235\n",
      "EPOCH 6 Completed, Loss: 27.845\n",
      "EPOCH 7 Completed, Loss: 20.300\n",
      "EPOCH 8 Completed, Loss: 16.903\n",
      "EPOCH 9 Completed, Loss: 22.315\n",
      "EPOCH 10 Completed, Loss: 12.602\n",
      "EPOCH 11 Completed, Loss: 8.973\n",
      "EPOCH 12 Completed, Loss: 11.571\n",
      "EPOCH 13 Completed, Loss: 6.837\n",
      "EPOCH 14 Completed, Loss: 6.188\n",
      "EPOCH 15 Completed, Loss: 8.765\n",
      "EPOCH 16 Completed, Loss: 8.456\n",
      "EPOCH 17 Completed, Loss: 8.182\n",
      "EPOCH 18 Completed, Loss: 10.059\n",
      "EPOCH 19 Completed, Loss: 6.709\n",
      "EPOCH 20 Completed, Loss: 12.118\n",
      "EPOCH 21 Completed, Loss: 3.810\n",
      "EPOCH 22 Completed, Loss: 7.308\n",
      "EPOCH 23 Completed, Loss: 7.195\n",
      "EPOCH 24 Completed, Loss: 6.539\n",
      "EPOCH 25 Completed, Loss: 6.599\n",
      "EPOCH 26 Completed, Loss: 8.472\n",
      "EPOCH 27 Completed, Loss: 4.260\n",
      "EPOCH 28 Completed, Loss: 4.488\n",
      "EPOCH 29 Completed, Loss: 4.201\n",
      "EPOCH 30 Completed, Loss: 4.346\n",
      "EPOCH 31 Completed, Loss: 4.099\n",
      "EPOCH 32 Completed, Loss: 2.905\n",
      "EPOCH 33 Completed, Loss: 2.297\n",
      "EPOCH 34 Completed, Loss: 3.449\n",
      "EPOCH 35 Completed, Loss: 2.598\n",
      "EPOCH 36 Completed, Loss: 4.123\n",
      "EPOCH 37 Completed, Loss: 2.781\n",
      "EPOCH 38 Completed, Loss: 3.950\n",
      "EPOCH 39 Completed, Loss: 2.749\n",
      "EPOCH 40 Completed, Loss: 2.958\n",
      "EPOCH 41 Completed, Loss: 3.119\n",
      "EPOCH 42 Completed, Loss: 3.286\n",
      "EPOCH 43 Completed, Loss: 2.090\n",
      "EPOCH 44 Completed, Loss: 1.865\n",
      "EPOCH 45 Completed, Loss: 3.230\n",
      "EPOCH 46 Completed, Loss: 2.161\n",
      "EPOCH 47 Completed, Loss: 2.809\n",
      "EPOCH 48 Completed, Loss: 2.554\n",
      "EPOCH 49 Completed, Loss: 2.939\n",
      "EPOCH 50 Completed, Loss: 2.284\n",
      "EPOCH 51 Completed, Loss: 2.192\n",
      "EPOCH 52 Completed, Loss: 2.752\n",
      "EPOCH 53 Completed, Loss: 2.456\n",
      "EPOCH 54 Completed, Loss: 3.249\n",
      "EPOCH 55 Completed, Loss: 2.549\n",
      "EPOCH 56 Completed, Loss: 2.483\n",
      "EPOCH 57 Completed, Loss: 2.472\n",
      "EPOCH 58 Completed, Loss: 2.683\n",
      "EPOCH 59 Completed, Loss: 2.340\n",
      "EPOCH 60 Completed, Loss: 1.743\n",
      "EPOCH 61 Completed, Loss: 2.608\n",
      "EPOCH 62 Completed, Loss: 1.350\n",
      "EPOCH 63 Completed, Loss: 2.073\n",
      "EPOCH 64 Completed, Loss: 1.666\n",
      "EPOCH 65 Completed, Loss: 3.036\n",
      "EPOCH 66 Completed, Loss: 2.402\n",
      "EPOCH 67 Completed, Loss: 2.264\n",
      "EPOCH 68 Completed, Loss: 1.684\n",
      "EPOCH 69 Completed, Loss: 2.904\n",
      "EPOCH 70 Completed, Loss: 1.941\n",
      "EPOCH 71 Completed, Loss: 1.329\n",
      "EPOCH 72 Completed, Loss: 1.595\n",
      "EPOCH 73 Completed, Loss: 1.557\n",
      "EPOCH 74 Completed, Loss: 2.041\n",
      "EPOCH 75 Completed, Loss: 2.556\n",
      "EPOCH 76 Completed, Loss: 3.168\n",
      "EPOCH 77 Completed, Loss: 1.870\n",
      "EPOCH 78 Completed, Loss: 2.981\n",
      "EPOCH 79 Completed, Loss: 1.408\n",
      "EPOCH 80 Completed, Loss: 1.978\n",
      "EPOCH 81 Completed, Loss: 2.234\n",
      "EPOCH 82 Completed, Loss: 2.089\n",
      "EPOCH 83 Completed, Loss: 2.079\n",
      "EPOCH 84 Completed, Loss: 2.700\n",
      "EPOCH 85 Completed, Loss: 1.305\n",
      "EPOCH 86 Completed, Loss: 2.117\n",
      "EPOCH 87 Completed, Loss: 1.734\n",
      "EPOCH 88 Completed, Loss: 2.071\n",
      "EPOCH 89 Completed, Loss: 1.912\n",
      "EPOCH 90 Completed, Loss: 2.077\n",
      "EPOCH 91 Completed, Loss: 2.631\n",
      "EPOCH 92 Completed, Loss: 1.781\n",
      "EPOCH 93 Completed, Loss: 1.571\n",
      "EPOCH 94 Completed, Loss: 2.586\n",
      "EPOCH 95 Completed, Loss: 1.357\n",
      "EPOCH 96 Completed, Loss: 2.247\n",
      "EPOCH 97 Completed, Loss: 1.911\n",
      "EPOCH 98 Completed, Loss: 1.745\n",
      "EPOCH 99 Completed, Loss: 2.461\n",
      "EPOCH 100 Completed, Loss: 2.213\n",
      "Total time: 0:00:00.623557\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    # Shuffle Data\n",
    "    idx = np.random.permutation(Z.shape[0])\n",
    "    x_temp = Z[idx]\n",
    "    y_temp = y[idx]\n",
    "    \n",
    "    for batch in range(Z.shape[0]//BATCH_SIZE):\n",
    "        batch_X = x_temp[batch*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "        batch_y = y_temp[batch*BATCH_SIZE:(batch+1)*BATCH_SIZE].reshape(1,-1)\n",
    "        \n",
    "        pred  = forward(batch_X, weights)\n",
    "        loss  = MSE(batch_X, batch_y, pred)\n",
    "        grads = compute_grads(batch_X, batch_y, pred)\n",
    "        \n",
    "        weights = update_weights(weights, grads, LR)\n",
    "    \n",
    "    print('EPOCH %d Completed, Loss: %.3f' % (epoch+1, loss))\n",
    "    \n",
    "end = datetime.now()\n",
    "print('Total time:', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "019e6eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.77692512,  2.96445189, -4.01457452,  1.04649802, -6.98131819]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0b62ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.91055003,  3.00048444, -4.01521986,  1.00538649, -6.98619243])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25ca5d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
