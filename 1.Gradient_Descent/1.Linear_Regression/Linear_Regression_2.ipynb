{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e198236b",
   "metadata": {},
   "source": [
    "# Solving Linear Regression \n",
    "\n",
    "- Only Training set, No Test points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7776a0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c61f7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "with open('data.pickle', 'rb') as f:\n",
    "    data_load = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c039be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4183967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3360, 4) (3360,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74133960",
   "metadata": {},
   "source": [
    "### Analytic Solution\n",
    "\n",
    "Let $X \\in \\mathbb{R}^{N \\times d}$ be the ***design matrix*** of the data,\n",
    "that is, the $i$ th **row vector** of $X$ is $\\hat{x^i} = (1, x^i)$.\n",
    "\n",
    "Let $y \\in \\mathbb{R}^N$ be the **row vector** consisting of labels of data.\n",
    "\n",
    "Then, the loss function $L(w)$ can be written as the following vector notation:\n",
    "$$L(w) = \\frac{1}{2N}\\sum_{i=1}^N (y_i- w x_i^\\top)^2=\\frac{1}{2N}(y - w X^\\top) (y - wX^\\top)^\\top.$$\n",
    "\n",
    "Since the loss function is convex w.r.t $w$, we can find the minimum by differentiating the function w.r.t $w$.\n",
    "\n",
    "$$\\nabla_{w} L(w) = \\frac{1}{N} (-yX + wX^\\top X)$$\n",
    "\n",
    "Therefore, if $X^\\top X$ is invertible, the analytic optimal solution is\n",
    "$$ \\hat{w} = yX(X^\\top X)^{-1}. $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1485d2bb",
   "metadata": {},
   "source": [
    "```np.linalg.solve(A,b)```\n",
    "\n",
    "- It finds a solution x for the linear equation Ax = b.\n",
    "- Here, x is considered to be a column vector. Thus we take transpose to the equation above.\n",
    "\n",
    "$$\\nabla_{w} L(w) = 0 \\quad \\Leftrightarrow \\quad w(X^\\top X)=yX \\quad \\Leftrightarrow \\quad (X^\\top X)w^\\top = X^\\top y^\\top$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a14c104d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.55513795 -4.01374667  3.66918128 -6.52875621]\n"
     ]
    }
   ],
   "source": [
    "w = np.linalg.solve(X.T @ X, X.T @ y.T)\n",
    "\n",
    "print(w)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a038c189",
   "metadata": {},
   "source": [
    "### Wrong Answer! Why?\n",
    "\n",
    "- We consider each row vector to have $1$ in the first entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4405c5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.zeros((X.shape[0], X.shape[1]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7e9955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X.shape[0]):\n",
    "    temp = list(X[i])\n",
    "    temp.insert(0, 1)  #List.insert(index, value) index에 value값을 넣기\n",
    "    Z[i] = np.array(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ffd4288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.04876171  3.00710683 -4.01374667  0.99925961 -6.99523963]\n"
     ]
    }
   ],
   "source": [
    "w = np.linalg.solve(Z.T@Z, Z.T@y.T)\n",
    "\n",
    "print(w)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd17d355",
   "metadata": {},
   "source": [
    "### Gradient Descent Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce243fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM=4\n",
    "OUTPUT_DIM=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50dc24a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X, weights):\n",
    "    pred = np.matmul(weights, X.T)\n",
    "    return pred\n",
    "\n",
    "def MSE(X, y, pred):\n",
    "    N = X.shape[0]\n",
    "    loss = np.sum((pred-y)**2) / (2*N)\n",
    "    return loss\n",
    "\n",
    "def compute_grads(X, y, pred):\n",
    "    N     = X.shape[0]\n",
    "    grads = (1/N)*(-np.matmul(y,X) + np.matmul(pred, X))\n",
    "    return grads\n",
    "\n",
    "def update_weights(weights, grads, LR):\n",
    "    weights -= LR*grads\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3980ae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE= 30\n",
    "EPOCHS=100\n",
    "LR = 0.001\n",
    "\n",
    "weights= np.random.randn(OUTPUT_DIM,INPUT_DIM+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd8ed066",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 Completed, Loss: 61.203\n",
      "EPOCH 2 Completed, Loss: 46.396\n",
      "EPOCH 3 Completed, Loss: 48.768\n",
      "EPOCH 4 Completed, Loss: 37.166\n",
      "EPOCH 5 Completed, Loss: 22.763\n",
      "EPOCH 6 Completed, Loss: 31.793\n",
      "EPOCH 7 Completed, Loss: 19.022\n",
      "EPOCH 8 Completed, Loss: 16.954\n",
      "EPOCH 9 Completed, Loss: 26.537\n",
      "EPOCH 10 Completed, Loss: 16.139\n",
      "EPOCH 11 Completed, Loss: 8.386\n",
      "EPOCH 12 Completed, Loss: 18.828\n",
      "EPOCH 13 Completed, Loss: 10.373\n",
      "EPOCH 14 Completed, Loss: 5.088\n",
      "EPOCH 15 Completed, Loss: 11.323\n",
      "EPOCH 16 Completed, Loss: 11.857\n",
      "EPOCH 17 Completed, Loss: 9.606\n",
      "EPOCH 18 Completed, Loss: 6.893\n",
      "EPOCH 19 Completed, Loss: 4.001\n",
      "EPOCH 20 Completed, Loss: 7.441\n",
      "EPOCH 21 Completed, Loss: 6.911\n",
      "EPOCH 22 Completed, Loss: 5.818\n",
      "EPOCH 23 Completed, Loss: 5.314\n",
      "EPOCH 24 Completed, Loss: 6.947\n",
      "EPOCH 25 Completed, Loss: 3.857\n",
      "EPOCH 26 Completed, Loss: 2.711\n",
      "EPOCH 27 Completed, Loss: 4.845\n",
      "EPOCH 28 Completed, Loss: 4.719\n",
      "EPOCH 29 Completed, Loss: 3.115\n",
      "EPOCH 30 Completed, Loss: 5.426\n",
      "EPOCH 31 Completed, Loss: 4.690\n",
      "EPOCH 32 Completed, Loss: 4.054\n",
      "EPOCH 33 Completed, Loss: 1.699\n",
      "EPOCH 34 Completed, Loss: 4.457\n",
      "EPOCH 35 Completed, Loss: 4.124\n",
      "EPOCH 36 Completed, Loss: 3.126\n",
      "EPOCH 37 Completed, Loss: 4.896\n",
      "EPOCH 38 Completed, Loss: 3.227\n",
      "EPOCH 39 Completed, Loss: 1.991\n",
      "EPOCH 40 Completed, Loss: 2.322\n",
      "EPOCH 41 Completed, Loss: 2.205\n",
      "EPOCH 42 Completed, Loss: 3.370\n",
      "EPOCH 43 Completed, Loss: 2.073\n",
      "EPOCH 44 Completed, Loss: 2.002\n",
      "EPOCH 45 Completed, Loss: 3.072\n",
      "EPOCH 46 Completed, Loss: 2.055\n",
      "EPOCH 47 Completed, Loss: 2.833\n",
      "EPOCH 48 Completed, Loss: 2.576\n",
      "EPOCH 49 Completed, Loss: 2.036\n",
      "EPOCH 50 Completed, Loss: 2.379\n",
      "EPOCH 51 Completed, Loss: 2.435\n",
      "EPOCH 52 Completed, Loss: 1.995\n",
      "EPOCH 53 Completed, Loss: 1.903\n",
      "EPOCH 54 Completed, Loss: 2.174\n",
      "EPOCH 55 Completed, Loss: 1.870\n",
      "EPOCH 56 Completed, Loss: 2.934\n",
      "EPOCH 57 Completed, Loss: 2.205\n",
      "EPOCH 58 Completed, Loss: 2.085\n",
      "EPOCH 59 Completed, Loss: 2.430\n",
      "EPOCH 60 Completed, Loss: 2.069\n",
      "EPOCH 61 Completed, Loss: 2.009\n",
      "EPOCH 62 Completed, Loss: 2.143\n",
      "EPOCH 63 Completed, Loss: 2.901\n",
      "EPOCH 64 Completed, Loss: 2.550\n",
      "EPOCH 65 Completed, Loss: 1.986\n",
      "EPOCH 66 Completed, Loss: 1.364\n",
      "EPOCH 67 Completed, Loss: 1.844\n",
      "EPOCH 68 Completed, Loss: 2.127\n",
      "EPOCH 69 Completed, Loss: 3.089\n",
      "EPOCH 70 Completed, Loss: 1.476\n",
      "EPOCH 71 Completed, Loss: 2.510\n",
      "EPOCH 72 Completed, Loss: 2.526\n",
      "EPOCH 73 Completed, Loss: 1.282\n",
      "EPOCH 74 Completed, Loss: 2.202\n",
      "EPOCH 75 Completed, Loss: 1.961\n",
      "EPOCH 76 Completed, Loss: 2.572\n",
      "EPOCH 77 Completed, Loss: 1.906\n",
      "EPOCH 78 Completed, Loss: 2.525\n",
      "EPOCH 79 Completed, Loss: 2.238\n",
      "EPOCH 80 Completed, Loss: 1.627\n",
      "EPOCH 81 Completed, Loss: 1.943\n",
      "EPOCH 82 Completed, Loss: 2.160\n",
      "EPOCH 83 Completed, Loss: 1.763\n",
      "EPOCH 84 Completed, Loss: 2.670\n",
      "EPOCH 85 Completed, Loss: 1.815\n",
      "EPOCH 86 Completed, Loss: 2.190\n",
      "EPOCH 87 Completed, Loss: 1.613\n",
      "EPOCH 88 Completed, Loss: 2.107\n",
      "EPOCH 89 Completed, Loss: 1.777\n",
      "EPOCH 90 Completed, Loss: 2.229\n",
      "EPOCH 91 Completed, Loss: 1.604\n",
      "EPOCH 92 Completed, Loss: 2.545\n",
      "EPOCH 93 Completed, Loss: 1.808\n",
      "EPOCH 94 Completed, Loss: 2.527\n",
      "EPOCH 95 Completed, Loss: 1.704\n",
      "EPOCH 96 Completed, Loss: 2.535\n",
      "EPOCH 97 Completed, Loss: 1.852\n",
      "EPOCH 98 Completed, Loss: 2.334\n",
      "EPOCH 99 Completed, Loss: 1.878\n",
      "EPOCH 100 Completed, Loss: 1.739\n",
      "Total time: 0:00:00.269953\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    # Shuffle Data\n",
    "    idx = np.random.permutation(Z.shape[0])\n",
    "    x_temp = Z[idx]\n",
    "    y_temp = y[idx]\n",
    "    \n",
    "    for batch in range(Z.shape[0]//BATCH_SIZE):\n",
    "        batch_X = x_temp[batch*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n",
    "        batch_y = y_temp[batch*BATCH_SIZE:(batch+1)*BATCH_SIZE].reshape(1,-1)\n",
    "        \n",
    "        pred  = forward(batch_X, weights)\n",
    "        loss  = MSE(batch_X, batch_y, pred)\n",
    "        grads = compute_grads(batch_X, batch_y, pred)\n",
    "        \n",
    "        weights = update_weights(weights, grads, LR)\n",
    "    \n",
    "    print('EPOCH %d Completed, Loss: %.3f' % (epoch+1, loss))\n",
    "    \n",
    "end = datetime.now()\n",
    "print('Total time:', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "019e6eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.92044363,  2.97188297, -4.01358441,  1.03781138, -6.98832044]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0b62ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.04876171,  3.00710683, -4.01374667,  0.99925961, -6.99523963])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25ca5d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
