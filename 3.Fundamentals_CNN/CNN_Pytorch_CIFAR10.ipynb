{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aENjWha3KApZ"
      },
      "source": [
        "CNN with CIFAR-10 data(Pytorch)\n",
        "==========="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import pakages\n",
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "c8EdXUqvIEVe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\user\\.conda\\envs\\test\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
            "c:\\Users\\user\\.conda\\envs\\test\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
            "c:\\Users\\user\\.conda\\envs\\test\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
            "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn\n",
        "from torchsummary import summary as summary_\n",
        "from torch import optim\n",
        "\n",
        "from keras.datasets import cifar10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download datas\n",
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "d6kxGFAqIETZ"
      },
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preprocess datas\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "N82C-hZPI3D5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[[ 59  62  63]\n",
            "   [ 43  46  45]\n",
            "   [ 50  48  43]\n",
            "   ...\n",
            "   [158 132 108]\n",
            "   [152 125 102]\n",
            "   [148 124 103]]\n",
            "\n",
            "  [[ 16  20  20]\n",
            "   [  0   0   0]\n",
            "   [ 18   8   0]\n",
            "   ...\n",
            "   [123  88  55]\n",
            "   [119  83  50]\n",
            "   [122  87  57]]\n",
            "\n",
            "  [[ 25  24  21]\n",
            "   [ 16   7   0]\n",
            "   [ 49  27   8]\n",
            "   ...\n",
            "   [118  84  50]\n",
            "   [120  84  50]\n",
            "   [109  73  42]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[208 170  96]\n",
            "   [201 153  34]\n",
            "   [198 161  26]\n",
            "   ...\n",
            "   [160 133  70]\n",
            "   [ 56  31   7]\n",
            "   [ 53  34  20]]\n",
            "\n",
            "  [[180 139  96]\n",
            "   [173 123  42]\n",
            "   [186 144  30]\n",
            "   ...\n",
            "   [184 148  94]\n",
            "   [ 97  62  34]\n",
            "   [ 83  53  34]]\n",
            "\n",
            "  [[177 144 116]\n",
            "   [168 129  94]\n",
            "   [179 142  87]\n",
            "   ...\n",
            "   [216 184 140]\n",
            "   [151 118  84]\n",
            "   [123  92  72]]]\n",
            "\n",
            "\n",
            " [[[154 177 187]\n",
            "   [126 137 136]\n",
            "   [105 104  95]\n",
            "   ...\n",
            "   [ 91  95  71]\n",
            "   [ 87  90  71]\n",
            "   [ 79  81  70]]\n",
            "\n",
            "  [[140 160 169]\n",
            "   [145 153 154]\n",
            "   [125 125 118]\n",
            "   ...\n",
            "   [ 96  99  78]\n",
            "   [ 77  80  62]\n",
            "   [ 71  73  61]]\n",
            "\n",
            "  [[140 155 164]\n",
            "   [139 146 149]\n",
            "   [115 115 112]\n",
            "   ...\n",
            "   [ 79  82  64]\n",
            "   [ 68  70  55]\n",
            "   [ 67  69  55]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[175 167 166]\n",
            "   [156 154 160]\n",
            "   [154 160 170]\n",
            "   ...\n",
            "   [ 42  34  36]\n",
            "   [ 61  53  57]\n",
            "   [ 93  83  91]]\n",
            "\n",
            "  [[165 154 128]\n",
            "   [156 152 130]\n",
            "   [159 161 142]\n",
            "   ...\n",
            "   [103  93  96]\n",
            "   [123 114 120]\n",
            "   [131 121 131]]\n",
            "\n",
            "  [[163 148 120]\n",
            "   [158 148 122]\n",
            "   [163 156 133]\n",
            "   ...\n",
            "   [143 133 139]\n",
            "   [143 134 142]\n",
            "   [143 133 144]]]\n",
            "\n",
            "\n",
            " [[[255 255 255]\n",
            "   [253 253 253]\n",
            "   [253 253 253]\n",
            "   ...\n",
            "   [253 253 253]\n",
            "   [253 253 253]\n",
            "   [253 253 253]]\n",
            "\n",
            "  [[255 255 255]\n",
            "   [255 255 255]\n",
            "   [255 255 255]\n",
            "   ...\n",
            "   [255 255 255]\n",
            "   [255 255 255]\n",
            "   [255 255 255]]\n",
            "\n",
            "  [[255 255 255]\n",
            "   [254 254 254]\n",
            "   [254 254 254]\n",
            "   ...\n",
            "   [254 254 254]\n",
            "   [254 254 254]\n",
            "   [254 254 254]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[113 120 112]\n",
            "   [111 118 111]\n",
            "   [105 112 106]\n",
            "   ...\n",
            "   [ 72  81  80]\n",
            "   [ 72  80  79]\n",
            "   [ 72  80  79]]\n",
            "\n",
            "  [[111 118 110]\n",
            "   [104 111 104]\n",
            "   [ 99 106  98]\n",
            "   ...\n",
            "   [ 68  75  73]\n",
            "   [ 70  76  75]\n",
            "   [ 78  84  82]]\n",
            "\n",
            "  [[106 113 105]\n",
            "   [ 99 106  98]\n",
            "   [ 95 102  94]\n",
            "   ...\n",
            "   [ 78  85  83]\n",
            "   [ 79  85  83]\n",
            "   [ 80  86  84]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 35 178 235]\n",
            "   [ 40 176 239]\n",
            "   [ 42 176 241]\n",
            "   ...\n",
            "   [ 99 177 219]\n",
            "   [ 79 147 197]\n",
            "   [ 89 148 189]]\n",
            "\n",
            "  [[ 57 182 234]\n",
            "   [ 44 184 250]\n",
            "   [ 50 183 240]\n",
            "   ...\n",
            "   [156 182 200]\n",
            "   [141 177 206]\n",
            "   [116 149 175]]\n",
            "\n",
            "  [[ 98 197 237]\n",
            "   [ 64 189 252]\n",
            "   [ 69 192 245]\n",
            "   ...\n",
            "   [188 195 206]\n",
            "   [119 135 147]\n",
            "   [ 61  79  90]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 73  79  77]\n",
            "   [ 53  63  68]\n",
            "   [ 54  68  80]\n",
            "   ...\n",
            "   [ 17  40  64]\n",
            "   [ 21  36  51]\n",
            "   [ 33  48  49]]\n",
            "\n",
            "  [[ 61  68  75]\n",
            "   [ 55  70  86]\n",
            "   [ 57  79 103]\n",
            "   ...\n",
            "   [ 24  48  72]\n",
            "   [ 17  35  53]\n",
            "   [  7  23  32]]\n",
            "\n",
            "  [[ 44  56  73]\n",
            "   [ 46  66  88]\n",
            "   [ 49  77 105]\n",
            "   ...\n",
            "   [ 27  52  77]\n",
            "   [ 21  43  66]\n",
            "   [ 12  31  50]]]\n",
            "\n",
            "\n",
            " [[[189 211 240]\n",
            "   [186 208 236]\n",
            "   [185 207 235]\n",
            "   ...\n",
            "   [175 195 224]\n",
            "   [172 194 222]\n",
            "   [169 194 220]]\n",
            "\n",
            "  [[194 210 239]\n",
            "   [191 207 236]\n",
            "   [190 206 235]\n",
            "   ...\n",
            "   [173 192 220]\n",
            "   [171 191 218]\n",
            "   [167 190 216]]\n",
            "\n",
            "  [[208 219 244]\n",
            "   [205 216 240]\n",
            "   [204 215 239]\n",
            "   ...\n",
            "   [175 191 217]\n",
            "   [172 190 216]\n",
            "   [169 191 215]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[207 199 181]\n",
            "   [203 195 175]\n",
            "   [203 196 173]\n",
            "   ...\n",
            "   [135 132 127]\n",
            "   [162 158 150]\n",
            "   [168 163 151]]\n",
            "\n",
            "  [[198 190 170]\n",
            "   [189 181 159]\n",
            "   [180 172 147]\n",
            "   ...\n",
            "   [178 171 160]\n",
            "   [175 169 156]\n",
            "   [175 169 154]]\n",
            "\n",
            "  [[198 189 173]\n",
            "   [189 181 162]\n",
            "   [178 170 149]\n",
            "   ...\n",
            "   [195 184 169]\n",
            "   [196 189 171]\n",
            "   [195 190 171]]]\n",
            "\n",
            "\n",
            " [[[229 229 239]\n",
            "   [236 237 247]\n",
            "   [234 236 247]\n",
            "   ...\n",
            "   [217 219 233]\n",
            "   [221 223 234]\n",
            "   [222 223 233]]\n",
            "\n",
            "  [[222 221 229]\n",
            "   [239 239 249]\n",
            "   [233 234 246]\n",
            "   ...\n",
            "   [223 223 236]\n",
            "   [227 228 238]\n",
            "   [210 211 220]]\n",
            "\n",
            "  [[213 206 211]\n",
            "   [234 232 239]\n",
            "   [231 233 244]\n",
            "   ...\n",
            "   [220 220 232]\n",
            "   [220 219 232]\n",
            "   [202 203 215]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[150 143 135]\n",
            "   [140 135 127]\n",
            "   [132 127 120]\n",
            "   ...\n",
            "   [224 222 218]\n",
            "   [230 228 225]\n",
            "   [241 241 238]]\n",
            "\n",
            "  [[137 132 126]\n",
            "   [130 127 120]\n",
            "   [125 121 115]\n",
            "   ...\n",
            "   [181 180 178]\n",
            "   [202 201 198]\n",
            "   [212 211 207]]\n",
            "\n",
            "  [[122 119 114]\n",
            "   [118 116 110]\n",
            "   [120 116 111]\n",
            "   ...\n",
            "   [179 177 173]\n",
            "   [164 164 162]\n",
            "   [163 163 161]]]]\n",
            "(50000, 32, 32, 3)\n",
            "uint8\n"
          ]
        }
      ],
      "source": [
        "print(X_train)\n",
        "print(X_train.shape)\n",
        "print(X_train.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[6]\n",
            " [9]\n",
            " [9]\n",
            " ...\n",
            " [9]\n",
            " [1]\n",
            " [1]]\n",
            "(50000, 1)\n",
            "uint8\n"
          ]
        }
      ],
      "source": [
        "print(y_train)\n",
        "print(y_train.shape)\n",
        "print(y_train.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[[0.23137255 0.24313725 0.24705882]\n",
            "   [0.16862745 0.18039216 0.17647059]\n",
            "   [0.19607843 0.18823529 0.16862745]\n",
            "   ...\n",
            "   [0.61960784 0.51764706 0.42352941]\n",
            "   [0.59607843 0.49019608 0.4       ]\n",
            "   [0.58039216 0.48627451 0.40392157]]\n",
            "\n",
            "  [[0.0627451  0.07843137 0.07843137]\n",
            "   [0.         0.         0.        ]\n",
            "   [0.07058824 0.03137255 0.        ]\n",
            "   ...\n",
            "   [0.48235294 0.34509804 0.21568627]\n",
            "   [0.46666667 0.3254902  0.19607843]\n",
            "   [0.47843137 0.34117647 0.22352941]]\n",
            "\n",
            "  [[0.09803922 0.09411765 0.08235294]\n",
            "   [0.0627451  0.02745098 0.        ]\n",
            "   [0.19215686 0.10588235 0.03137255]\n",
            "   ...\n",
            "   [0.4627451  0.32941176 0.19607843]\n",
            "   [0.47058824 0.32941176 0.19607843]\n",
            "   [0.42745098 0.28627451 0.16470588]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.81568627 0.66666667 0.37647059]\n",
            "   [0.78823529 0.6        0.13333333]\n",
            "   [0.77647059 0.63137255 0.10196078]\n",
            "   ...\n",
            "   [0.62745098 0.52156863 0.2745098 ]\n",
            "   [0.21960784 0.12156863 0.02745098]\n",
            "   [0.20784314 0.13333333 0.07843137]]\n",
            "\n",
            "  [[0.70588235 0.54509804 0.37647059]\n",
            "   [0.67843137 0.48235294 0.16470588]\n",
            "   [0.72941176 0.56470588 0.11764706]\n",
            "   ...\n",
            "   [0.72156863 0.58039216 0.36862745]\n",
            "   [0.38039216 0.24313725 0.13333333]\n",
            "   [0.3254902  0.20784314 0.13333333]]\n",
            "\n",
            "  [[0.69411765 0.56470588 0.45490196]\n",
            "   [0.65882353 0.50588235 0.36862745]\n",
            "   [0.70196078 0.55686275 0.34117647]\n",
            "   ...\n",
            "   [0.84705882 0.72156863 0.54901961]\n",
            "   [0.59215686 0.4627451  0.32941176]\n",
            "   [0.48235294 0.36078431 0.28235294]]]\n",
            "\n",
            "\n",
            " [[[0.60392157 0.69411765 0.73333333]\n",
            "   [0.49411765 0.5372549  0.53333333]\n",
            "   [0.41176471 0.40784314 0.37254902]\n",
            "   ...\n",
            "   [0.35686275 0.37254902 0.27843137]\n",
            "   [0.34117647 0.35294118 0.27843137]\n",
            "   [0.30980392 0.31764706 0.2745098 ]]\n",
            "\n",
            "  [[0.54901961 0.62745098 0.6627451 ]\n",
            "   [0.56862745 0.6        0.60392157]\n",
            "   [0.49019608 0.49019608 0.4627451 ]\n",
            "   ...\n",
            "   [0.37647059 0.38823529 0.30588235]\n",
            "   [0.30196078 0.31372549 0.24313725]\n",
            "   [0.27843137 0.28627451 0.23921569]]\n",
            "\n",
            "  [[0.54901961 0.60784314 0.64313725]\n",
            "   [0.54509804 0.57254902 0.58431373]\n",
            "   [0.45098039 0.45098039 0.43921569]\n",
            "   ...\n",
            "   [0.30980392 0.32156863 0.25098039]\n",
            "   [0.26666667 0.2745098  0.21568627]\n",
            "   [0.2627451  0.27058824 0.21568627]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.68627451 0.65490196 0.65098039]\n",
            "   [0.61176471 0.60392157 0.62745098]\n",
            "   [0.60392157 0.62745098 0.66666667]\n",
            "   ...\n",
            "   [0.16470588 0.13333333 0.14117647]\n",
            "   [0.23921569 0.20784314 0.22352941]\n",
            "   [0.36470588 0.3254902  0.35686275]]\n",
            "\n",
            "  [[0.64705882 0.60392157 0.50196078]\n",
            "   [0.61176471 0.59607843 0.50980392]\n",
            "   [0.62352941 0.63137255 0.55686275]\n",
            "   ...\n",
            "   [0.40392157 0.36470588 0.37647059]\n",
            "   [0.48235294 0.44705882 0.47058824]\n",
            "   [0.51372549 0.4745098  0.51372549]]\n",
            "\n",
            "  [[0.63921569 0.58039216 0.47058824]\n",
            "   [0.61960784 0.58039216 0.47843137]\n",
            "   [0.63921569 0.61176471 0.52156863]\n",
            "   ...\n",
            "   [0.56078431 0.52156863 0.54509804]\n",
            "   [0.56078431 0.5254902  0.55686275]\n",
            "   [0.56078431 0.52156863 0.56470588]]]\n",
            "\n",
            "\n",
            " [[[1.         1.         1.        ]\n",
            "   [0.99215686 0.99215686 0.99215686]\n",
            "   [0.99215686 0.99215686 0.99215686]\n",
            "   ...\n",
            "   [0.99215686 0.99215686 0.99215686]\n",
            "   [0.99215686 0.99215686 0.99215686]\n",
            "   [0.99215686 0.99215686 0.99215686]]\n",
            "\n",
            "  [[1.         1.         1.        ]\n",
            "   [1.         1.         1.        ]\n",
            "   [1.         1.         1.        ]\n",
            "   ...\n",
            "   [1.         1.         1.        ]\n",
            "   [1.         1.         1.        ]\n",
            "   [1.         1.         1.        ]]\n",
            "\n",
            "  [[1.         1.         1.        ]\n",
            "   [0.99607843 0.99607843 0.99607843]\n",
            "   [0.99607843 0.99607843 0.99607843]\n",
            "   ...\n",
            "   [0.99607843 0.99607843 0.99607843]\n",
            "   [0.99607843 0.99607843 0.99607843]\n",
            "   [0.99607843 0.99607843 0.99607843]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.44313725 0.47058824 0.43921569]\n",
            "   [0.43529412 0.4627451  0.43529412]\n",
            "   [0.41176471 0.43921569 0.41568627]\n",
            "   ...\n",
            "   [0.28235294 0.31764706 0.31372549]\n",
            "   [0.28235294 0.31372549 0.30980392]\n",
            "   [0.28235294 0.31372549 0.30980392]]\n",
            "\n",
            "  [[0.43529412 0.4627451  0.43137255]\n",
            "   [0.40784314 0.43529412 0.40784314]\n",
            "   [0.38823529 0.41568627 0.38431373]\n",
            "   ...\n",
            "   [0.26666667 0.29411765 0.28627451]\n",
            "   [0.2745098  0.29803922 0.29411765]\n",
            "   [0.30588235 0.32941176 0.32156863]]\n",
            "\n",
            "  [[0.41568627 0.44313725 0.41176471]\n",
            "   [0.38823529 0.41568627 0.38431373]\n",
            "   [0.37254902 0.4        0.36862745]\n",
            "   ...\n",
            "   [0.30588235 0.33333333 0.3254902 ]\n",
            "   [0.30980392 0.33333333 0.3254902 ]\n",
            "   [0.31372549 0.3372549  0.32941176]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[0.1372549  0.69803922 0.92156863]\n",
            "   [0.15686275 0.69019608 0.9372549 ]\n",
            "   [0.16470588 0.69019608 0.94509804]\n",
            "   ...\n",
            "   [0.38823529 0.69411765 0.85882353]\n",
            "   [0.30980392 0.57647059 0.77254902]\n",
            "   [0.34901961 0.58039216 0.74117647]]\n",
            "\n",
            "  [[0.22352941 0.71372549 0.91764706]\n",
            "   [0.17254902 0.72156863 0.98039216]\n",
            "   [0.19607843 0.71764706 0.94117647]\n",
            "   ...\n",
            "   [0.61176471 0.71372549 0.78431373]\n",
            "   [0.55294118 0.69411765 0.80784314]\n",
            "   [0.45490196 0.58431373 0.68627451]]\n",
            "\n",
            "  [[0.38431373 0.77254902 0.92941176]\n",
            "   [0.25098039 0.74117647 0.98823529]\n",
            "   [0.27058824 0.75294118 0.96078431]\n",
            "   ...\n",
            "   [0.7372549  0.76470588 0.80784314]\n",
            "   [0.46666667 0.52941176 0.57647059]\n",
            "   [0.23921569 0.30980392 0.35294118]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.28627451 0.30980392 0.30196078]\n",
            "   [0.20784314 0.24705882 0.26666667]\n",
            "   [0.21176471 0.26666667 0.31372549]\n",
            "   ...\n",
            "   [0.06666667 0.15686275 0.25098039]\n",
            "   [0.08235294 0.14117647 0.2       ]\n",
            "   [0.12941176 0.18823529 0.19215686]]\n",
            "\n",
            "  [[0.23921569 0.26666667 0.29411765]\n",
            "   [0.21568627 0.2745098  0.3372549 ]\n",
            "   [0.22352941 0.30980392 0.40392157]\n",
            "   ...\n",
            "   [0.09411765 0.18823529 0.28235294]\n",
            "   [0.06666667 0.1372549  0.20784314]\n",
            "   [0.02745098 0.09019608 0.1254902 ]]\n",
            "\n",
            "  [[0.17254902 0.21960784 0.28627451]\n",
            "   [0.18039216 0.25882353 0.34509804]\n",
            "   [0.19215686 0.30196078 0.41176471]\n",
            "   ...\n",
            "   [0.10588235 0.20392157 0.30196078]\n",
            "   [0.08235294 0.16862745 0.25882353]\n",
            "   [0.04705882 0.12156863 0.19607843]]]\n",
            "\n",
            "\n",
            " [[[0.74117647 0.82745098 0.94117647]\n",
            "   [0.72941176 0.81568627 0.9254902 ]\n",
            "   [0.7254902  0.81176471 0.92156863]\n",
            "   ...\n",
            "   [0.68627451 0.76470588 0.87843137]\n",
            "   [0.6745098  0.76078431 0.87058824]\n",
            "   [0.6627451  0.76078431 0.8627451 ]]\n",
            "\n",
            "  [[0.76078431 0.82352941 0.9372549 ]\n",
            "   [0.74901961 0.81176471 0.9254902 ]\n",
            "   [0.74509804 0.80784314 0.92156863]\n",
            "   ...\n",
            "   [0.67843137 0.75294118 0.8627451 ]\n",
            "   [0.67058824 0.74901961 0.85490196]\n",
            "   [0.65490196 0.74509804 0.84705882]]\n",
            "\n",
            "  [[0.81568627 0.85882353 0.95686275]\n",
            "   [0.80392157 0.84705882 0.94117647]\n",
            "   [0.8        0.84313725 0.9372549 ]\n",
            "   ...\n",
            "   [0.68627451 0.74901961 0.85098039]\n",
            "   [0.6745098  0.74509804 0.84705882]\n",
            "   [0.6627451  0.74901961 0.84313725]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.81176471 0.78039216 0.70980392]\n",
            "   [0.79607843 0.76470588 0.68627451]\n",
            "   [0.79607843 0.76862745 0.67843137]\n",
            "   ...\n",
            "   [0.52941176 0.51764706 0.49803922]\n",
            "   [0.63529412 0.61960784 0.58823529]\n",
            "   [0.65882353 0.63921569 0.59215686]]\n",
            "\n",
            "  [[0.77647059 0.74509804 0.66666667]\n",
            "   [0.74117647 0.70980392 0.62352941]\n",
            "   [0.70588235 0.6745098  0.57647059]\n",
            "   ...\n",
            "   [0.69803922 0.67058824 0.62745098]\n",
            "   [0.68627451 0.6627451  0.61176471]\n",
            "   [0.68627451 0.6627451  0.60392157]]\n",
            "\n",
            "  [[0.77647059 0.74117647 0.67843137]\n",
            "   [0.74117647 0.70980392 0.63529412]\n",
            "   [0.69803922 0.66666667 0.58431373]\n",
            "   ...\n",
            "   [0.76470588 0.72156863 0.6627451 ]\n",
            "   [0.76862745 0.74117647 0.67058824]\n",
            "   [0.76470588 0.74509804 0.67058824]]]\n",
            "\n",
            "\n",
            " [[[0.89803922 0.89803922 0.9372549 ]\n",
            "   [0.9254902  0.92941176 0.96862745]\n",
            "   [0.91764706 0.9254902  0.96862745]\n",
            "   ...\n",
            "   [0.85098039 0.85882353 0.91372549]\n",
            "   [0.86666667 0.8745098  0.91764706]\n",
            "   [0.87058824 0.8745098  0.91372549]]\n",
            "\n",
            "  [[0.87058824 0.86666667 0.89803922]\n",
            "   [0.9372549  0.9372549  0.97647059]\n",
            "   [0.91372549 0.91764706 0.96470588]\n",
            "   ...\n",
            "   [0.8745098  0.8745098  0.9254902 ]\n",
            "   [0.89019608 0.89411765 0.93333333]\n",
            "   [0.82352941 0.82745098 0.8627451 ]]\n",
            "\n",
            "  [[0.83529412 0.80784314 0.82745098]\n",
            "   [0.91764706 0.90980392 0.9372549 ]\n",
            "   [0.90588235 0.91372549 0.95686275]\n",
            "   ...\n",
            "   [0.8627451  0.8627451  0.90980392]\n",
            "   [0.8627451  0.85882353 0.90980392]\n",
            "   [0.79215686 0.79607843 0.84313725]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.58823529 0.56078431 0.52941176]\n",
            "   [0.54901961 0.52941176 0.49803922]\n",
            "   [0.51764706 0.49803922 0.47058824]\n",
            "   ...\n",
            "   [0.87843137 0.87058824 0.85490196]\n",
            "   [0.90196078 0.89411765 0.88235294]\n",
            "   [0.94509804 0.94509804 0.93333333]]\n",
            "\n",
            "  [[0.5372549  0.51764706 0.49411765]\n",
            "   [0.50980392 0.49803922 0.47058824]\n",
            "   [0.49019608 0.4745098  0.45098039]\n",
            "   ...\n",
            "   [0.70980392 0.70588235 0.69803922]\n",
            "   [0.79215686 0.78823529 0.77647059]\n",
            "   [0.83137255 0.82745098 0.81176471]]\n",
            "\n",
            "  [[0.47843137 0.46666667 0.44705882]\n",
            "   [0.4627451  0.45490196 0.43137255]\n",
            "   [0.47058824 0.45490196 0.43529412]\n",
            "   ...\n",
            "   [0.70196078 0.69411765 0.67843137]\n",
            "   [0.64313725 0.64313725 0.63529412]\n",
            "   [0.63921569 0.63921569 0.63137255]]]]\n",
            "(50000, 32, 32, 3)\n",
            "float64\n"
          ]
        }
      ],
      "source": [
        "print(X_train)\n",
        "print(X_train.shape)\n",
        "print(X_train.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Qx9eW1foJ35J"
      },
      "outputs": [],
      "source": [
        "y_train = np.array(y_train, dtype=np.int8)\n",
        "y_test = np.array(y_test, dtype=np.int8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[6]\n",
            " [9]\n",
            " [9]\n",
            " ...\n",
            " [9]\n",
            " [1]\n",
            " [1]]\n",
            "(50000, 1)\n",
            "int8\n"
          ]
        }
      ],
      "source": [
        "print(y_train)\n",
        "print(y_train.shape)\n",
        "print(y_train.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we use a CNN model with Pytorch, we need to change the shape of dataset as\n",
        "$\\left( N, C, H, W \\right)$.\n",
        "\n",
        "$N$ means the number of data.\n",
        "\n",
        "$C$ means the number of channel.\n",
        "\n",
        "$H$, $W$ mean the size of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(50000, 3, 32, 32)\n"
          ]
        }
      ],
      "source": [
        "X_train = np.reshape(X_train,(-1,3,32,32))\n",
        "X_test = np.reshape(X_test,(-1,3,32,32))\n",
        "\n",
        "print(X_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RXZfZfk_KuIM"
      },
      "outputs": [],
      "source": [
        "X_train = torch.Tensor(X_train)\n",
        "X_test = torch.Tensor(X_test)\n",
        "y_train = torch.LongTensor(y_train)\n",
        "y_test = torch.LongTensor(y_test)\n",
        "\n",
        "ds_train = TensorDataset(X_train, y_train)\n",
        "ds_test = TensorDataset(X_test, y_test)\n",
        "\n",
        "loader_train = DataLoader(ds_train, batch_size=64, shuffle=True)\n",
        "loader_test = DataLoader(ds_test, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "data, target = next(iter(loader_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([64, 1])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Construct model\n",
        "-----\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pythorch provides a convolutional neural network layer through the command \"torch.nn.Conv2d\".\n",
        "\n",
        "Also, we need a (max/average) pooling layer during CNN model.\n",
        "\n",
        "Pythorch provides a pooling layer through the command \"torch.nn.MaxPool2d\", \"torch.nn.AvgPool2d\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "torch.nn.Conv2d\n",
        "------\n",
        "torch.nn.Conv2d has 3 essential inputs (in_channels / out_channels / kernel_size)\n",
        "\n",
        "in_channels : the number of channels of input data\n",
        "\n",
        "out_channels : the number of channels of output data\n",
        "\n",
        "kernel_size : the size of kernel "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "torch.nn.Conv2d has other inessential inputs(stride / padding / padding_mode / dilation / bias etc.)\n",
        "\n",
        "stride : the stride of the convolution - default = 1\n",
        "\n",
        "padding : the length of padding - default = 0\n",
        "\n",
        "padding_mode : how method of padding('zeros', 'reflect', 'replicate', 'circular') - default = 'zeros'\n",
        "\n",
        "dilation : spacing between kernel elements - default = 1\n",
        "\n",
        "bias : whether adding a learnable bias to the output - default = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "output size formular is\n",
        "\n",
        "![ex_screenshot](./output_form.jpg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxB0RIFZKvrP",
        "outputId": "935c198b-65d2-46f0-bea7-a4f6551041ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]             896\n",
            "              ReLU-2           [-1, 32, 32, 32]               0\n",
            "         MaxPool2d-3           [-1, 32, 16, 16]               0\n",
            "            Conv2d-4           [-1, 64, 16, 16]          18,496\n",
            "              ReLU-5           [-1, 64, 16, 16]               0\n",
            "         MaxPool2d-6             [-1, 64, 8, 8]               0\n",
            "           Flatten-7                 [-1, 4096]               0\n",
            "            Linear-8                  [-1, 512]       2,097,664\n",
            "              ReLU-9                  [-1, 512]               0\n",
            "           Linear-10                   [-1, 64]          32,832\n",
            "             ReLU-11                   [-1, 64]               0\n",
            "           Linear-12                   [-1, 10]             650\n",
            "================================================================\n",
            "Total params: 2,150,538\n",
            "Trainable params: 2,150,538\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.88\n",
            "Params size (MB): 8.20\n",
            "Estimated Total Size (MB): 9.10\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = nn.Sequential()\n",
        "model.add_module('conv1',nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1, padding_mode='zeros'))\n",
        "model.add_module('relu1',nn.ReLU())\n",
        "model.add_module('pool1',nn.MaxPool2d(2,2))\n",
        "model.add_module('conv2',nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1, padding_mode='zeros'))\n",
        "model.add_module('relu2',nn.ReLU())\n",
        "model.add_module('pool2',nn.MaxPool2d(2,2))\n",
        "model.add_module('flatten',nn.Flatten())\n",
        "model.add_module('fc1', nn.Linear(in_features=64*8*8, out_features=512))\n",
        "model.add_module('relu3', nn.ReLU())\n",
        "model.add_module('fc2', nn.Linear(in_features=512, out_features=64))\n",
        "model.add_module('relu4', nn.ReLU())\n",
        "model.add_module('fc3', nn.Linear(in_features=64, out_features=10))\n",
        "\n",
        "summary_(model,input_size=(3,32,32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sVFu4BykKytd"
      },
      "outputs": [],
      "source": [
        "# 오차함수 선택\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# 가중치를 학습하기 위한 최적화 기법 선택\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bnWQPYfyK53N"
      },
      "outputs": [],
      "source": [
        "def train(epoch):\n",
        "    model.train()  # 신경망을 학습 모드로 전환\n",
        "\n",
        "    # 데이터로더에서 미니배치를 하나씩 꺼내 학습을 수행\n",
        "    for data, targets in loader_train:\n",
        "\n",
        "        optimizer.zero_grad()  # 경사를 0으로 초기화\n",
        "        outputs = model(data)  # 데이터를 입력하고 출력을 계산\n",
        "        loss = loss_fn(outputs, targets.squeeze(dim=-1))  # 출력과 훈련 데이터 정답 간의 오차를 계산\n",
        "        loss.backward()  # 오차를 역전파 계산\n",
        "        optimizer.step()  # 역전파 계산한 값으로 가중치를 수정\n",
        "\n",
        "    print(\"epoch{}：완료\\n\".format(epoch+1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "aSQNpDsDK7b7"
      },
      "outputs": [],
      "source": [
        "def test():\n",
        "    model.eval()  # 신경망을 추론 모드로 전환\n",
        "    correct = 0\n",
        "\n",
        "    # 데이터로더에서 미니배치를 하나씩 꺼내 추론을 수행\n",
        "    with torch.no_grad():  # 추론 과정에는 미분이 필요없음\n",
        "        for data, targets in loader_test:\n",
        "\n",
        "            outputs = model(data)  # 데이터를 입력하고 출력을 계산\n",
        "\n",
        "            # 추론 계산\n",
        "            _, predicted = torch.max(outputs.data, 1)  # 확률이 가장 높은 레이블이 무엇인지 계산\n",
        "            correct += predicted.eq(targets.data.view_as(predicted)).sum()  # 정답과 일치한 경우 정답 카운트를 증가\n",
        "\n",
        "    # 정확도 출력\n",
        "    data_num = len(loader_test.dataset)  # 데이터 총 건수\n",
        "    print('\\n테스트 데이터에서 예측 정확도: {}/{} ({:.2f}%)\\n'.format(correct,\n",
        "                                                   data_num, 100. * float(correct) / float(data_num)))\n",
        "    return float(correct) / float(data_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "예측 결과 : 5\n",
            "이 이미지 데이터의 정답 레이블 : 7\n"
          ]
        }
      ],
      "source": [
        "index = np.random.randint(10000)\n",
        "\n",
        "model.eval()  # 신경망을 추론 모드로 전환\n",
        "data = X_test[index]\n",
        "data = data.view([-1,3,32,32])\n",
        "output = model(data)  # 데이터를 입력하고 출력을 계산\n",
        "_, predicted = torch.max(output.data, 1)  # 확률이 가장 높은 레이블이 무엇인지 계산\n",
        "\n",
        "print(\"예측 결과 : \" + str(predicted.item()))\n",
        "print(\"이 이미지 데이터의 정답 레이블 : \" + str(y_test[index].item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before training\n",
        "-----\n",
        "We can test the model before training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBTyrwJUK9iv",
        "outputId": "b6f2596b-8c7a-4e0e-d4f5-e23f763d29ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "테스트 데이터에서 예측 정확도: 1000/10000 (10.00%)\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.1"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training\n",
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BYZnrHiMknN",
        "outputId": "f25ab683-4f23-41e6-eb77-fcc2e58b5dd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch1：완료\n",
            "\n",
            "\n",
            "테스트 데이터에서 예측 정확도: 4170/10000 (41.70%)\n",
            "\n",
            "epoch2：완료\n",
            "\n",
            "\n",
            "테스트 데이터에서 예측 정확도: 4475/10000 (44.75%)\n",
            "\n",
            "epoch3：완료\n",
            "\n",
            "\n",
            "테스트 데이터에서 예측 정확도: 4903/10000 (49.03%)\n",
            "\n",
            "epoch4：완료\n",
            "\n",
            "\n",
            "테스트 데이터에서 예측 정확도: 5091/10000 (50.91%)\n",
            "\n",
            "epoch5：완료\n",
            "\n",
            "\n",
            "테스트 데이터에서 예측 정확도: 5114/10000 (51.14%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "acc = []\n",
        "MAX_ITERATION=5\n",
        "for epoch in range(MAX_ITERATION):\n",
        "    train(epoch)\n",
        "    acc.append(test())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Rx3WD5hcMzHB",
        "outputId": "5527b01c-9e69-42af-d1d9-ed1be7b93fc3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x2373e86b3a0>]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check the model with data in testset\n",
        "------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "예측 결과 : 7\n",
            "이 이미지 데이터의 정답 레이블 : 7\n"
          ]
        }
      ],
      "source": [
        "model.eval()  # 신경망을 추론 모드로 전환\n",
        "data = X_test[index]\n",
        "data = data.view([-1,3,32,32])\n",
        "output = model(data)  # 데이터를 입력하고 출력을 계산\n",
        "_, predicted = torch.max(output.data, 1)  # 확률이 가장 높은 레이블이 무엇인지 계산\n",
        "\n",
        "print(\"예측 결과 : \" + str(predicted.item()))\n",
        "print(\"이 이미지 데이터의 정답 레이블 : \" + str(y_test[index].item()))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 ('test')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "b45ccf6fd3c8427b2d1b5e880d896f46770117107f616a4b6b7de4d4387dfaf4"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
